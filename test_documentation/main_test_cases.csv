test_id,dataset_name,model_name,model_description,target_column,n_features,n_samples_train,n_samples_test,dataset_type,imbalance_ratio,complexity_level,train_accuracy,test_accuracy,overfitting_gap,overfitting_severity,primary_test_objective,secondary_objectives,expected_accuracy_range,expected_precision_range,expected_recall_range,expected_f1_range,expected_auc_range,expected_top_features,feature_importance_validation,shap_analysis_focus,ui_load_time_expectation,chart_rendering_check,data_accuracy_check,responsiveness_check,optimal_threshold_expectation,threshold_sensitivity_check,roc_curve_expectation,auc_interpretation,ai_explanation_trigger,explanation_relevance,explanation_accuracy,edge_cases,pass_criteria,fail_criteria,testing_notes,expected_challenges,model_file_path,scaler_file_path,train_dataset_path,test_dataset_path,test_status,test_date,tester_name,actual_results,issues_found,test_verdict
customer_segmentation_prediction_random_forest_balanced,Customer Segmentation Prediction,random_forest_balanced,Well-balanced Random Forest,customer_segment,11,1120,480,Mixed Categorical-Numerical,1.0,Medium,0.9982,0.9146,0.0836,Mild,Test mixed feature type handling,Test AI explanation generation; Validate chart rendering performance; Test responsive design elements,0.86 - 0.96,0.75 - 0.95,0.70 - 0.90,0.83 - 0.93,0.88 - 0.96,numerical features and encoded categories,Feature importance should be logically distributed,Categorical feature impact analysis,< 5 seconds,All charts display correctly,Metrics match backend calculations,UI responsive on different screen sizes,Optimal threshold around 0.5,Precision-recall tradeoff visible,ROC curve should bow strongly toward top-left,Excellent discrimination (AUC > 0.85),Test AI explanation button functionality,AI explanations should be contextually relevant,AI should correctly interpret the metrics,Test with different browser sizes; Check chart zoom and interaction features; Verify AI explanation with complex cases,All metrics display correctly; Charts render without errors; AI explanations generate successfully,"Any crashes, incorrect calculations, missing charts, or non-responsive UI elements",Focus on general performance metrics and interpretability,Standard classification analysis,test_datasets\customer_segmentation_prediction\random_forest_balanced_model.joblib,,test_datasets/customer_segmentation_prediction/train_dataset.csv,test_datasets/customer_segmentation_prediction/test_dataset.csv,Not Started,,,,,
customer_segmentation_prediction_random_forest_overfitted,Customer Segmentation Prediction,random_forest_overfitted,Potentially overfitted Random Forest,customer_segment,11,1120,480,Mixed Categorical-Numerical,1.0,Medium,1.0,0.9167,0.0833,Mild,Test mixed feature type handling + Overfitting detection,Validate overfitting warning systems; Test AI explanation generation; Validate chart rendering performance; Test responsive design elements,0.87 - 0.97,0.75 - 0.95,0.70 - 0.90,0.84 - 0.94,0.89 - 0.97,numerical features and encoded categories,Feature importance should be logically distributed,Categorical feature impact analysis,< 5 seconds,All charts display correctly,Metrics match backend calculations,UI responsive on different screen sizes,Optimal threshold around 0.5,Precision-recall tradeoff visible,ROC curve should bow strongly toward top-left,Excellent discrimination (AUC > 0.85),Test AI explanation button functionality,AI explanations should be contextually relevant,AI should correctly interpret the metrics,Check if overfitting warning appears; Test with different browser sizes; Check chart zoom and interaction features; Verify AI explanation with complex cases,All metrics display correctly; Charts render without errors; AI explanations generate successfully,"Any crashes, incorrect calculations, missing charts, or non-responsive UI elements",Focus on overfitting detection and warnings,Large performance gap between train/test,test_datasets\customer_segmentation_prediction\random_forest_overfitted_model.joblib,,test_datasets/customer_segmentation_prediction/train_dataset.csv,test_datasets/customer_segmentation_prediction/test_dataset.csv,Not Started,,,,,
customer_segmentation_prediction_gradient_boosting,Customer Segmentation Prediction,gradient_boosting,Gradient Boosting Classifier,customer_segment,11,1120,480,Mixed Categorical-Numerical,1.0,Medium,1.0,0.9271,0.0729,Mild,Test mixed feature type handling,Test AI explanation generation; Validate chart rendering performance; Test responsive design elements,0.88 - 0.98,0.75 - 0.95,0.70 - 0.90,0.85 - 0.95,0.90 - 0.98,numerical features and encoded categories,Feature importance should be logically distributed,Categorical feature impact analysis,< 5 seconds,All charts display correctly,Metrics match backend calculations,UI responsive on different screen sizes,Optimal threshold around 0.5,Precision-recall tradeoff visible,ROC curve should bow strongly toward top-left,Excellent discrimination (AUC > 0.85),Test AI explanation button functionality,AI explanations should be contextually relevant,AI should correctly interpret the metrics,Test with different browser sizes; Check chart zoom and interaction features; Verify AI explanation with complex cases,All metrics display correctly; Charts render without errors; AI explanations generate successfully,"Any crashes, incorrect calculations, missing charts, or non-responsive UI elements",Focus on general performance metrics and interpretability,Standard classification analysis,test_datasets\customer_segmentation_prediction\gradient_boosting_model.joblib,,test_datasets/customer_segmentation_prediction/train_dataset.csv,test_datasets/customer_segmentation_prediction/test_dataset.csv,Not Started,,,,,
customer_segmentation_prediction_logistic_regression,Customer Segmentation Prediction,logistic_regression,Logistic Regression,customer_segment,11,1120,480,Mixed Categorical-Numerical,1.0,Medium,0.9295,0.9333,-0.0039,None/Minimal,Test mixed feature type handling,Test AI explanation generation; Validate chart rendering performance; Test responsive design elements,0.88 - 0.98,0.75 - 0.95,0.70 - 0.90,0.85 - 0.95,0.90 - 0.98,numerical features and encoded categories,Feature importance should be logically distributed,Categorical feature impact analysis,< 5 seconds,All charts display correctly,Metrics match backend calculations,UI responsive on different screen sizes,Optimal threshold around 0.5,Precision-recall tradeoff visible,ROC curve should bow strongly toward top-left,Excellent discrimination (AUC > 0.85),Test AI explanation button functionality,AI explanations should be contextually relevant,AI should correctly interpret the metrics,Test with different browser sizes; Check chart zoom and interaction features; Verify AI explanation with complex cases,All metrics display correctly; Charts render without errors; AI explanations generate successfully,"Any crashes, incorrect calculations, missing charts, or non-responsive UI elements",Focus on general performance metrics and interpretability,Standard classification analysis,test_datasets\customer_segmentation_prediction\logistic_regression_model.joblib,test_datasets\customer_segmentation_prediction\logistic_regression_scaler.joblib,test_datasets/customer_segmentation_prediction/train_dataset.csv,test_datasets/customer_segmentation_prediction/test_dataset.csv,Not Started,,,,,
customer_segmentation_prediction_decision_tree_simple,Customer Segmentation Prediction,decision_tree_simple,Simple Decision Tree,customer_segment,11,1120,480,Mixed Categorical-Numerical,1.0,Medium,0.9223,0.8583,0.064,Mild,Test mixed feature type handling,Test AI explanation generation; Validate chart rendering performance; Test responsive design elements,0.81 - 0.91,0.75 - 0.95,0.70 - 0.90,0.78 - 0.88,0.83 - 0.91,numerical features and encoded categories,Feature importance should be logically distributed,Categorical feature impact analysis,< 5 seconds,All charts display correctly,Metrics match backend calculations,UI responsive on different screen sizes,Optimal threshold around 0.5,Precision-recall tradeoff visible,ROC curve should bow strongly toward top-left,Excellent discrimination (AUC > 0.85),Test AI explanation button functionality,AI explanations should be contextually relevant,AI should correctly interpret the metrics,Test with different browser sizes; Check chart zoom and interaction features; Verify AI explanation with complex cases,All metrics display correctly; Charts render without errors; AI explanations generate successfully,"Any crashes, incorrect calculations, missing charts, or non-responsive UI elements",Focus on general performance metrics and interpretability,Standard classification analysis,test_datasets\customer_segmentation_prediction\decision_tree_simple_model.joblib,,test_datasets/customer_segmentation_prediction/train_dataset.csv,test_datasets/customer_segmentation_prediction/test_dataset.csv,Not Started,,,,,
customer_segmentation_prediction_extra_trees,Customer Segmentation Prediction,extra_trees,Extra Trees Classifier,customer_segment,11,1120,480,Mixed Categorical-Numerical,1.0,Medium,0.9982,0.9167,0.0815,Mild,Test mixed feature type handling,Test AI explanation generation; Validate chart rendering performance; Test responsive design elements,0.87 - 0.97,0.75 - 0.95,0.70 - 0.90,0.84 - 0.94,0.89 - 0.97,numerical features and encoded categories,Feature importance should be logically distributed,Categorical feature impact analysis,< 5 seconds,All charts display correctly,Metrics match backend calculations,UI responsive on different screen sizes,Optimal threshold around 0.5,Precision-recall tradeoff visible,ROC curve should bow strongly toward top-left,Excellent discrimination (AUC > 0.85),Test AI explanation button functionality,AI explanations should be contextually relevant,AI should correctly interpret the metrics,Test with different browser sizes; Check chart zoom and interaction features; Verify AI explanation with complex cases,All metrics display correctly; Charts render without errors; AI explanations generate successfully,"Any crashes, incorrect calculations, missing charts, or non-responsive UI elements",Focus on general performance metrics and interpretability,Standard classification analysis,test_datasets\customer_segmentation_prediction\extra_trees_model.joblib,,test_datasets/customer_segmentation_prediction/train_dataset.csv,test_datasets/customer_segmentation_prediction/test_dataset.csv,Not Started,,,,,
financial_approval_prediction_random_forest_balanced,Financial Approval Prediction,random_forest_balanced,Well-balanced Random Forest,approval_status,20,1400,600,High-dimensional Balanced,1.01,Medium-High,0.9986,0.9283,0.0702,Mild,Test feature importance ranking and model interpretability,Test AI explanation generation; Validate chart rendering performance; Test responsive design elements,0.88 - 0.98,0.75 - 0.95,0.70 - 0.90,0.85 - 0.95,0.90 - 0.98,"income_score, credit_history, debt_ratio, savings_amount",Financial features should rank higher than demographic ones,Individual prediction explanations for edge cases,< 5 seconds,All charts display correctly,Metrics match backend calculations,UI responsive on different screen sizes,Optimal threshold around 0.5,Precision-recall tradeoff visible,ROC curve should bow strongly toward top-left,Excellent discrimination (AUC > 0.85),Test AI explanation button functionality,AI explanations should be contextually relevant,AI should correctly interpret the metrics,Test with different browser sizes; Check chart zoom and interaction features; Verify AI explanation with complex cases,All metrics display correctly; Charts render without errors; AI explanations generate successfully,"Any crashes, incorrect calculations, missing charts, or non-responsive UI elements",Focus on general performance metrics and interpretability,Standard classification analysis,test_datasets\financial_approval_prediction\random_forest_balanced_model.joblib,,test_datasets/financial_approval_prediction/train_dataset.csv,test_datasets/financial_approval_prediction/test_dataset.csv,Not Started,,,,,
financial_approval_prediction_random_forest_overfitted,Financial Approval Prediction,random_forest_overfitted,Potentially overfitted Random Forest,approval_status,20,1400,600,High-dimensional Balanced,1.01,Medium-High,1.0,0.9367,0.0633,Mild,Test feature importance ranking and model interpretability + Overfitting detection,Validate overfitting warning systems; Test AI explanation generation; Validate chart rendering performance; Test responsive design elements,0.89 - 0.99,0.75 - 0.95,0.70 - 0.90,0.86 - 0.96,0.91 - 0.99,"income_score, credit_history, debt_ratio, savings_amount",Financial features should rank higher than demographic ones,Individual prediction explanations for edge cases,< 5 seconds,All charts display correctly,Metrics match backend calculations,UI responsive on different screen sizes,Optimal threshold around 0.5,Precision-recall tradeoff visible,ROC curve should bow strongly toward top-left,Excellent discrimination (AUC > 0.85),Test AI explanation button functionality,AI explanations should be contextually relevant,AI should correctly interpret the metrics,Check if overfitting warning appears; Test with different browser sizes; Check chart zoom and interaction features; Verify AI explanation with complex cases,All metrics display correctly; Charts render without errors; AI explanations generate successfully,"Any crashes, incorrect calculations, missing charts, or non-responsive UI elements",Focus on overfitting detection and warnings,Large performance gap between train/test,test_datasets\financial_approval_prediction\random_forest_overfitted_model.joblib,,test_datasets/financial_approval_prediction/train_dataset.csv,test_datasets/financial_approval_prediction/test_dataset.csv,Not Started,,,,,
financial_approval_prediction_gradient_boosting,Financial Approval Prediction,gradient_boosting,Gradient Boosting Classifier,approval_status,20,1400,600,High-dimensional Balanced,1.01,Medium-High,1.0,0.9483,0.0517,Mild,Test feature importance ranking and model interpretability,Test AI explanation generation; Validate chart rendering performance; Test responsive design elements,0.90 - 1.00,0.75 - 0.95,0.70 - 0.90,0.87 - 0.97,0.92 - 1.00,"income_score, credit_history, debt_ratio, savings_amount",Financial features should rank higher than demographic ones,Individual prediction explanations for edge cases,< 5 seconds,All charts display correctly,Metrics match backend calculations,UI responsive on different screen sizes,Optimal threshold around 0.5,Precision-recall tradeoff visible,ROC curve should bow strongly toward top-left,Excellent discrimination (AUC > 0.85),Test AI explanation button functionality,AI explanations should be contextually relevant,AI should correctly interpret the metrics,Test with different browser sizes; Check chart zoom and interaction features; Verify AI explanation with complex cases,All metrics display correctly; Charts render without errors; AI explanations generate successfully,"Any crashes, incorrect calculations, missing charts, or non-responsive UI elements",Focus on general performance metrics and interpretability,Standard classification analysis,test_datasets\financial_approval_prediction\gradient_boosting_model.joblib,,test_datasets/financial_approval_prediction/train_dataset.csv,test_datasets/financial_approval_prediction/test_dataset.csv,Not Started,,,,,
financial_approval_prediction_logistic_regression,Financial Approval Prediction,logistic_regression,Logistic Regression,approval_status,20,1400,600,High-dimensional Balanced,1.01,Medium-High,0.8521,0.86,-0.0079,None/Minimal,Test feature importance ranking and model interpretability,Test AI explanation generation; Validate chart rendering performance; Test responsive design elements,0.81 - 0.91,0.75 - 0.95,0.70 - 0.90,0.78 - 0.88,0.83 - 0.91,"income_score, credit_history, debt_ratio, savings_amount",Financial features should rank higher than demographic ones,Individual prediction explanations for edge cases,< 5 seconds,All charts display correctly,Metrics match backend calculations,UI responsive on different screen sizes,Optimal threshold around 0.5,Precision-recall tradeoff visible,ROC curve should bow strongly toward top-left,Excellent discrimination (AUC > 0.85),Test AI explanation button functionality,AI explanations should be contextually relevant,AI should correctly interpret the metrics,Test with different browser sizes; Check chart zoom and interaction features; Verify AI explanation with complex cases,All metrics display correctly; Charts render without errors; AI explanations generate successfully,"Any crashes, incorrect calculations, missing charts, or non-responsive UI elements",Focus on general performance metrics and interpretability,Standard classification analysis,test_datasets\financial_approval_prediction\logistic_regression_model.joblib,test_datasets\financial_approval_prediction\logistic_regression_scaler.joblib,test_datasets/financial_approval_prediction/train_dataset.csv,test_datasets/financial_approval_prediction/test_dataset.csv,Not Started,,,,,
financial_approval_prediction_decision_tree_simple,Financial Approval Prediction,decision_tree_simple,Simple Decision Tree,approval_status,20,1400,600,High-dimensional Balanced,1.01,Medium-High,0.8971,0.8417,0.0555,Mild,Test feature importance ranking and model interpretability,Test AI explanation generation; Validate chart rendering performance; Test responsive design elements,0.79 - 0.89,0.75 - 0.95,0.70 - 0.90,0.76 - 0.86,0.81 - 0.89,"income_score, credit_history, debt_ratio, savings_amount",Financial features should rank higher than demographic ones,Individual prediction explanations for edge cases,< 5 seconds,All charts display correctly,Metrics match backend calculations,UI responsive on different screen sizes,Optimal threshold around 0.5,Precision-recall tradeoff visible,ROC curve should show good separation from diagonal,Good discrimination (AUC 0.75-0.85),Test AI explanation button functionality,AI explanations should be contextually relevant,AI should correctly interpret the metrics,Test with different browser sizes; Check chart zoom and interaction features; Verify AI explanation with complex cases,All metrics display correctly; Charts render without errors; AI explanations generate successfully,"Any crashes, incorrect calculations, missing charts, or non-responsive UI elements",Focus on general performance metrics and interpretability,Standard classification analysis,test_datasets\financial_approval_prediction\decision_tree_simple_model.joblib,,test_datasets/financial_approval_prediction/train_dataset.csv,test_datasets/financial_approval_prediction/test_dataset.csv,Not Started,,,,,
financial_approval_prediction_extra_trees,Financial Approval Prediction,extra_trees,Extra Trees Classifier,approval_status,20,1400,600,High-dimensional Balanced,1.01,Medium-High,0.9993,0.9317,0.0676,Mild,Test feature importance ranking and model interpretability,Test AI explanation generation; Validate chart rendering performance; Test responsive design elements,0.88 - 0.98,0.75 - 0.95,0.70 - 0.90,0.85 - 0.95,0.90 - 0.98,"income_score, credit_history, debt_ratio, savings_amount",Financial features should rank higher than demographic ones,Individual prediction explanations for edge cases,< 5 seconds,All charts display correctly,Metrics match backend calculations,UI responsive on different screen sizes,Optimal threshold around 0.5,Precision-recall tradeoff visible,ROC curve should bow strongly toward top-left,Excellent discrimination (AUC > 0.85),Test AI explanation button functionality,AI explanations should be contextually relevant,AI should correctly interpret the metrics,Test with different browser sizes; Check chart zoom and interaction features; Verify AI explanation with complex cases,All metrics display correctly; Charts render without errors; AI explanations generate successfully,"Any crashes, incorrect calculations, missing charts, or non-responsive UI elements",Focus on general performance metrics and interpretability,Standard classification analysis,test_datasets\financial_approval_prediction\extra_trees_model.joblib,,test_datasets/financial_approval_prediction/train_dataset.csv,test_datasets/financial_approval_prediction/test_dataset.csv,Not Started,,,,,
industrial_equipment_failure_prediction_random_forest_balanced,Industrial Equipment Failure Prediction,random_forest_balanced,Well-balanced Random Forest,equipment_failure,15,1260,540,Non-linear Complex,2.68,High,1.0,0.9222,0.0778,Mild,Test complex feature interaction detection,Test SHAP interaction plots; Validate complex feature explanations; Test AI explanation generation; Validate chart rendering performance; Test responsive design elements,0.87 - 0.97,0.70 - 0.90,0.65 - 0.85,0.84 - 0.94,0.89 - 0.97,sensor features and interaction terms,Feature importance should be logically distributed,Feature interaction plots and dependence analysis,< 5 seconds,All charts display correctly,Metrics match backend calculations,UI responsive on different screen sizes,Optimal threshold around 0.4-0.6,Precision-recall tradeoff visible,ROC curve should bow strongly toward top-left,Excellent discrimination (AUC > 0.85),Test AI explanation button functionality,AI explanations should be contextually relevant,AI should correctly interpret the metrics,Test with different browser sizes; Check chart zoom and interaction features; Verify AI explanation with complex cases,All metrics display correctly; Charts render without errors; AI explanations generate successfully; Precision-recall tradeoff should be evident,"Any crashes, incorrect calculations, missing charts, or non-responsive UI elements",Focus on feature interaction analysis,Standard classification analysis,test_datasets\industrial_equipment_failure_prediction\random_forest_balanced_model.joblib,,test_datasets/industrial_equipment_failure_prediction/train_dataset.csv,test_datasets/industrial_equipment_failure_prediction/test_dataset.csv,Not Started,,,,,
industrial_equipment_failure_prediction_random_forest_overfitted,Industrial Equipment Failure Prediction,random_forest_overfitted,Potentially overfitted Random Forest,equipment_failure,15,1260,540,Non-linear Complex,2.68,High,1.0,0.9315,0.0685,Mild,Test complex feature interaction detection + Overfitting detection,Validate overfitting warning systems; Test SHAP interaction plots; Validate complex feature explanations; Test AI explanation generation; Validate chart rendering performance; Test responsive design elements,0.88 - 0.98,0.70 - 0.90,0.65 - 0.85,0.85 - 0.95,0.90 - 0.98,sensor features and interaction terms,Feature importance should be logically distributed,Feature interaction plots and dependence analysis,< 5 seconds,All charts display correctly,Metrics match backend calculations,UI responsive on different screen sizes,Optimal threshold around 0.4-0.6,Precision-recall tradeoff visible,ROC curve should bow strongly toward top-left,Excellent discrimination (AUC > 0.85),Test AI explanation button functionality,AI explanations should be contextually relevant,AI should correctly interpret the metrics,Check if overfitting warning appears; Test with different browser sizes; Check chart zoom and interaction features; Verify AI explanation with complex cases,All metrics display correctly; Charts render without errors; AI explanations generate successfully; Precision-recall tradeoff should be evident,"Any crashes, incorrect calculations, missing charts, or non-responsive UI elements",Focus on overfitting detection and warnings,Large performance gap between train/test,test_datasets\industrial_equipment_failure_prediction\random_forest_overfitted_model.joblib,,test_datasets/industrial_equipment_failure_prediction/train_dataset.csv,test_datasets/industrial_equipment_failure_prediction/test_dataset.csv,Not Started,,,,,
industrial_equipment_failure_prediction_gradient_boosting,Industrial Equipment Failure Prediction,gradient_boosting,Gradient Boosting Classifier,equipment_failure,15,1260,540,Non-linear Complex,2.68,High,1.0,0.9481,0.0519,Mild,Test complex feature interaction detection,Test SHAP interaction plots; Validate complex feature explanations; Test AI explanation generation; Validate chart rendering performance; Test responsive design elements,0.90 - 1.00,0.70 - 0.90,0.65 - 0.85,0.87 - 0.97,0.92 - 1.00,sensor features and interaction terms,Feature importance should be logically distributed,Feature interaction plots and dependence analysis,< 5 seconds,All charts display correctly,Metrics match backend calculations,UI responsive on different screen sizes,Optimal threshold around 0.4-0.6,Precision-recall tradeoff visible,ROC curve should bow strongly toward top-left,Excellent discrimination (AUC > 0.85),Test AI explanation button functionality,AI explanations should be contextually relevant,AI should correctly interpret the metrics,Test with different browser sizes; Check chart zoom and interaction features; Verify AI explanation with complex cases,All metrics display correctly; Charts render without errors; AI explanations generate successfully; Precision-recall tradeoff should be evident,"Any crashes, incorrect calculations, missing charts, or non-responsive UI elements",Focus on feature interaction analysis,Standard classification analysis,test_datasets\industrial_equipment_failure_prediction\gradient_boosting_model.joblib,,test_datasets/industrial_equipment_failure_prediction/train_dataset.csv,test_datasets/industrial_equipment_failure_prediction/test_dataset.csv,Not Started,,,,,
industrial_equipment_failure_prediction_logistic_regression,Industrial Equipment Failure Prediction,logistic_regression,Logistic Regression,equipment_failure,15,1260,540,Non-linear Complex,2.68,High,0.9794,0.9759,0.0034,None/Minimal,Test complex feature interaction detection,Test SHAP interaction plots; Validate complex feature explanations; Test AI explanation generation; Validate chart rendering performance; Test responsive design elements,0.93 - 1.00,0.70 - 0.90,0.65 - 0.85,0.90 - 1.00,0.95 - 1.00,sensor features and interaction terms,Feature importance should be logically distributed,Feature interaction plots and dependence analysis,< 5 seconds,All charts display correctly,Metrics match backend calculations,UI responsive on different screen sizes,Optimal threshold around 0.4-0.6,Precision-recall tradeoff visible,ROC curve should bow strongly toward top-left,Excellent discrimination (AUC > 0.85),Test AI explanation button functionality,AI explanations should be contextually relevant,AI should correctly interpret the metrics,Test with different browser sizes; Check chart zoom and interaction features; Verify AI explanation with complex cases,All metrics display correctly; Charts render without errors; AI explanations generate successfully; Precision-recall tradeoff should be evident,"Any crashes, incorrect calculations, missing charts, or non-responsive UI elements",Focus on feature interaction analysis,Standard classification analysis,test_datasets\industrial_equipment_failure_prediction\logistic_regression_model.joblib,test_datasets\industrial_equipment_failure_prediction\logistic_regression_scaler.joblib,test_datasets/industrial_equipment_failure_prediction/train_dataset.csv,test_datasets/industrial_equipment_failure_prediction/test_dataset.csv,Not Started,,,,,
industrial_equipment_failure_prediction_decision_tree_simple,Industrial Equipment Failure Prediction,decision_tree_simple,Simple Decision Tree,equipment_failure,15,1260,540,Non-linear Complex,2.68,High,0.9532,0.8944,0.0587,Mild,Test complex feature interaction detection,Test SHAP interaction plots; Validate complex feature explanations; Test AI explanation generation; Validate chart rendering performance; Test responsive design elements,0.84 - 0.94,0.70 - 0.90,0.65 - 0.85,0.81 - 0.91,0.86 - 0.94,sensor features and interaction terms,Feature importance should be logically distributed,Feature interaction plots and dependence analysis,< 5 seconds,All charts display correctly,Metrics match backend calculations,UI responsive on different screen sizes,Optimal threshold around 0.4-0.6,Precision-recall tradeoff visible,ROC curve should bow strongly toward top-left,Excellent discrimination (AUC > 0.85),Test AI explanation button functionality,AI explanations should be contextually relevant,AI should correctly interpret the metrics,Test with different browser sizes; Check chart zoom and interaction features; Verify AI explanation with complex cases,All metrics display correctly; Charts render without errors; AI explanations generate successfully; Precision-recall tradeoff should be evident,"Any crashes, incorrect calculations, missing charts, or non-responsive UI elements",Focus on feature interaction analysis,Standard classification analysis,test_datasets\industrial_equipment_failure_prediction\decision_tree_simple_model.joblib,,test_datasets/industrial_equipment_failure_prediction/train_dataset.csv,test_datasets/industrial_equipment_failure_prediction/test_dataset.csv,Not Started,,,,,
industrial_equipment_failure_prediction_extra_trees,Industrial Equipment Failure Prediction,extra_trees,Extra Trees Classifier,equipment_failure,15,1260,540,Non-linear Complex,2.68,High,0.9833,0.8944,0.0889,Mild,Test complex feature interaction detection,Test SHAP interaction plots; Validate complex feature explanations; Test AI explanation generation; Validate chart rendering performance; Test responsive design elements,0.84 - 0.94,0.70 - 0.90,0.65 - 0.85,0.81 - 0.91,0.86 - 0.94,sensor features and interaction terms,Feature importance should be logically distributed,Feature interaction plots and dependence analysis,< 5 seconds,All charts display correctly,Metrics match backend calculations,UI responsive on different screen sizes,Optimal threshold around 0.4-0.6,Precision-recall tradeoff visible,ROC curve should bow strongly toward top-left,Excellent discrimination (AUC > 0.85),Test AI explanation button functionality,AI explanations should be contextually relevant,AI should correctly interpret the metrics,Test with different browser sizes; Check chart zoom and interaction features; Verify AI explanation with complex cases,All metrics display correctly; Charts render without errors; AI explanations generate successfully; Precision-recall tradeoff should be evident,"Any crashes, incorrect calculations, missing charts, or non-responsive UI elements",Focus on feature interaction analysis,Standard classification analysis,test_datasets\industrial_equipment_failure_prediction\extra_trees_model.joblib,,test_datasets/industrial_equipment_failure_prediction/train_dataset.csv,test_datasets/industrial_equipment_failure_prediction/test_dataset.csv,Not Started,,,,,
medical_disease_risk_prediction_random_forest_balanced,Medical Disease Risk Prediction,random_forest_balanced,Well-balanced Random Forest,disease_risk,15,1050,450,Imbalanced Binary,5.6,Medium,0.9895,0.9511,0.0384,None/Minimal,Test precision-recall balance and threshold optimization,Test false positive/negative analysis; Validate threshold sensitivity; Test AI explanation generation; Validate chart rendering performance; Test responsive design elements,0.90 - 1.00,0.60 - 0.85,0.50 - 0.80,0.87 - 0.97,0.92 - 1.00,"blood_pressure, cholesterol_level, glucose_level, bmi_score",Clinical measurements should have highest importance,Feature contributions for high-risk predictions,< 5 seconds,All charts display correctly,Metrics match backend calculations,UI responsive on different screen sizes,Optimal threshold should be < 0.5 (favoring recall),Precision-recall tradeoff visible,ROC curve should bow strongly toward top-left,Excellent discrimination (AUC > 0.85),Test AI explanation button functionality,AI explanations should be contextually relevant,AI should correctly interpret the metrics,Test with extreme threshold values; Check false positive implications; Test with different browser sizes; Check chart zoom and interaction features; Verify AI explanation with complex cases,All metrics display correctly; Charts render without errors; AI explanations generate successfully; Precision-recall tradeoff should be evident,"Any crashes, incorrect calculations, missing charts, or non-responsive UI elements",Focus on precision-recall optimization,Class imbalance may affect threshold selection,test_datasets\medical_disease_risk_prediction\random_forest_balanced_model.joblib,,test_datasets/medical_disease_risk_prediction/train_dataset.csv,test_datasets/medical_disease_risk_prediction/test_dataset.csv,Not Started,,,,,
medical_disease_risk_prediction_random_forest_overfitted,Medical Disease Risk Prediction,random_forest_overfitted,Potentially overfitted Random Forest,disease_risk,15,1050,450,Imbalanced Binary,5.6,Medium,1.0,0.9511,0.0489,None/Minimal,Test precision-recall balance and threshold optimization + Overfitting detection,Validate overfitting warning systems; Test false positive/negative analysis; Validate threshold sensitivity; Test AI explanation generation; Validate chart rendering performance; Test responsive design elements,0.90 - 1.00,0.60 - 0.85,0.50 - 0.80,0.87 - 0.97,0.92 - 1.00,"blood_pressure, cholesterol_level, glucose_level, bmi_score",Clinical measurements should have highest importance,Feature contributions for high-risk predictions,< 5 seconds,All charts display correctly,Metrics match backend calculations,UI responsive on different screen sizes,Optimal threshold should be < 0.5 (favoring recall),Precision-recall tradeoff visible,ROC curve should bow strongly toward top-left,Excellent discrimination (AUC > 0.85),Test AI explanation button functionality,AI explanations should be contextually relevant,AI should correctly interpret the metrics,Check if overfitting warning appears; Test with extreme threshold values; Check false positive implications; Test with different browser sizes; Check chart zoom and interaction features; Verify AI explanation with complex cases,All metrics display correctly; Charts render without errors; AI explanations generate successfully; Precision-recall tradeoff should be evident,"Any crashes, incorrect calculations, missing charts, or non-responsive UI elements",Focus on overfitting detection and warnings,Large performance gap between train/test; Class imbalance may affect threshold selection,test_datasets\medical_disease_risk_prediction\random_forest_overfitted_model.joblib,,test_datasets/medical_disease_risk_prediction/train_dataset.csv,test_datasets/medical_disease_risk_prediction/test_dataset.csv,Not Started,,,,,
medical_disease_risk_prediction_gradient_boosting,Medical Disease Risk Prediction,gradient_boosting,Gradient Boosting Classifier,disease_risk,15,1050,450,Imbalanced Binary,5.6,Medium,1.0,0.9467,0.0533,Mild,Test precision-recall balance and threshold optimization,Test false positive/negative analysis; Validate threshold sensitivity; Test AI explanation generation; Validate chart rendering performance; Test responsive design elements,0.90 - 1.00,0.60 - 0.85,0.50 - 0.80,0.87 - 0.97,0.92 - 1.00,"blood_pressure, cholesterol_level, glucose_level, bmi_score",Clinical measurements should have highest importance,Feature contributions for high-risk predictions,< 5 seconds,All charts display correctly,Metrics match backend calculations,UI responsive on different screen sizes,Optimal threshold should be < 0.5 (favoring recall),Precision-recall tradeoff visible,ROC curve should bow strongly toward top-left,Excellent discrimination (AUC > 0.85),Test AI explanation button functionality,AI explanations should be contextually relevant,AI should correctly interpret the metrics,Test with extreme threshold values; Check false positive implications; Test with different browser sizes; Check chart zoom and interaction features; Verify AI explanation with complex cases,All metrics display correctly; Charts render without errors; AI explanations generate successfully; Precision-recall tradeoff should be evident,"Any crashes, incorrect calculations, missing charts, or non-responsive UI elements",Focus on precision-recall optimization,Class imbalance may affect threshold selection,test_datasets\medical_disease_risk_prediction\gradient_boosting_model.joblib,,test_datasets/medical_disease_risk_prediction/train_dataset.csv,test_datasets/medical_disease_risk_prediction/test_dataset.csv,Not Started,,,,,
medical_disease_risk_prediction_logistic_regression,Medical Disease Risk Prediction,logistic_regression,Logistic Regression,disease_risk,15,1050,450,Imbalanced Binary,5.6,Medium,0.9667,0.9644,0.0022,None/Minimal,Test precision-recall balance and threshold optimization,Test false positive/negative analysis; Validate threshold sensitivity; Test AI explanation generation; Validate chart rendering performance; Test responsive design elements,0.91 - 1.00,0.60 - 0.85,0.50 - 0.80,0.88 - 0.98,0.93 - 1.00,"blood_pressure, cholesterol_level, glucose_level, bmi_score",Clinical measurements should have highest importance,Feature contributions for high-risk predictions,< 5 seconds,All charts display correctly,Metrics match backend calculations,UI responsive on different screen sizes,Optimal threshold should be < 0.5 (favoring recall),Precision-recall tradeoff visible,ROC curve should bow strongly toward top-left,Excellent discrimination (AUC > 0.85),Test AI explanation button functionality,AI explanations should be contextually relevant,AI should correctly interpret the metrics,Test with extreme threshold values; Check false positive implications; Test with different browser sizes; Check chart zoom and interaction features; Verify AI explanation with complex cases,All metrics display correctly; Charts render without errors; AI explanations generate successfully; Precision-recall tradeoff should be evident,"Any crashes, incorrect calculations, missing charts, or non-responsive UI elements",Focus on precision-recall optimization,Class imbalance may affect threshold selection,test_datasets\medical_disease_risk_prediction\logistic_regression_model.joblib,test_datasets\medical_disease_risk_prediction\logistic_regression_scaler.joblib,test_datasets/medical_disease_risk_prediction/train_dataset.csv,test_datasets/medical_disease_risk_prediction/test_dataset.csv,Not Started,,,,,
medical_disease_risk_prediction_decision_tree_simple,Medical Disease Risk Prediction,decision_tree_simple,Simple Decision Tree,disease_risk,15,1050,450,Imbalanced Binary,5.6,Medium,0.9476,0.9089,0.0387,None/Minimal,Test precision-recall balance and threshold optimization,Test false positive/negative analysis; Validate threshold sensitivity; Test AI explanation generation; Validate chart rendering performance; Test responsive design elements,0.86 - 0.96,0.60 - 0.85,0.50 - 0.80,0.83 - 0.93,0.88 - 0.96,"blood_pressure, cholesterol_level, glucose_level, bmi_score",Clinical measurements should have highest importance,Feature contributions for high-risk predictions,< 5 seconds,All charts display correctly,Metrics match backend calculations,UI responsive on different screen sizes,Optimal threshold should be < 0.5 (favoring recall),Precision-recall tradeoff visible,ROC curve should bow strongly toward top-left,Excellent discrimination (AUC > 0.85),Test AI explanation button functionality,AI explanations should be contextually relevant,AI should correctly interpret the metrics,Test with extreme threshold values; Check false positive implications; Test with different browser sizes; Check chart zoom and interaction features; Verify AI explanation with complex cases,All metrics display correctly; Charts render without errors; AI explanations generate successfully; Precision-recall tradeoff should be evident,"Any crashes, incorrect calculations, missing charts, or non-responsive UI elements",Focus on precision-recall optimization,Class imbalance may affect threshold selection,test_datasets\medical_disease_risk_prediction\decision_tree_simple_model.joblib,,test_datasets/medical_disease_risk_prediction/train_dataset.csv,test_datasets/medical_disease_risk_prediction/test_dataset.csv,Not Started,,,,,
medical_disease_risk_prediction_extra_trees,Medical Disease Risk Prediction,extra_trees,Extra Trees Classifier,disease_risk,15,1050,450,Imbalanced Binary,5.6,Medium,0.981,0.9311,0.0498,None/Minimal,Test precision-recall balance and threshold optimization,Test false positive/negative analysis; Validate threshold sensitivity; Test AI explanation generation; Validate chart rendering performance; Test responsive design elements,0.88 - 0.98,0.60 - 0.85,0.50 - 0.80,0.85 - 0.95,0.90 - 0.98,"blood_pressure, cholesterol_level, glucose_level, bmi_score",Clinical measurements should have highest importance,Feature contributions for high-risk predictions,< 5 seconds,All charts display correctly,Metrics match backend calculations,UI responsive on different screen sizes,Optimal threshold should be < 0.5 (favoring recall),Precision-recall tradeoff visible,ROC curve should bow strongly toward top-left,Excellent discrimination (AUC > 0.85),Test AI explanation button functionality,AI explanations should be contextually relevant,AI should correctly interpret the metrics,Test with extreme threshold values; Check false positive implications; Test with different browser sizes; Check chart zoom and interaction features; Verify AI explanation with complex cases,All metrics display correctly; Charts render without errors; AI explanations generate successfully; Precision-recall tradeoff should be evident,"Any crashes, incorrect calculations, missing charts, or non-responsive UI elements",Focus on precision-recall optimization,Class imbalance may affect threshold selection,test_datasets\medical_disease_risk_prediction\extra_trees_model.joblib,,test_datasets/medical_disease_risk_prediction/train_dataset.csv,test_datasets/medical_disease_risk_prediction/test_dataset.csv,Not Started,,,,,
noisy_feature_classification_random_forest_balanced,Noisy Feature Classification,random_forest_balanced,Well-balanced Random Forest,target_class,25,840,360,Low Signal-to-Noise,1.0,High,0.9988,0.8222,0.1766,Moderate,Test model robustness with irrelevant features,Test AI explanation generation; Validate chart rendering performance; Test responsive design elements,0.77 - 0.87,0.75 - 0.95,0.70 - 0.90,0.74 - 0.84,0.79 - 0.87,First 5 features should dominate,Only informative features should have significant importance,Verify noise features have minimal SHAP values,< 5 seconds,All charts display correctly,Metrics match backend calculations,UI responsive on different screen sizes,Optimal threshold around 0.5,Precision-recall tradeoff visible,ROC curve should show good separation from diagonal,Good discrimination (AUC 0.75-0.85),Test AI explanation button functionality,AI explanations should be contextually relevant,AI should correctly interpret the metrics,Test with different browser sizes; Check chart zoom and interaction features; Verify AI explanation with complex cases,All metrics display correctly; Charts render without errors; AI explanations generate successfully; Overfitting indicators should be visible,"Any crashes, incorrect calculations, missing charts, or non-responsive UI elements",Focus on general performance metrics and interpretability,Many features may show minimal importance,test_datasets\noisy_feature_classification\random_forest_balanced_model.joblib,,test_datasets/noisy_feature_classification/train_dataset.csv,test_datasets/noisy_feature_classification/test_dataset.csv,Not Started,,,,,
noisy_feature_classification_random_forest_overfitted,Noisy Feature Classification,random_forest_overfitted,Potentially overfitted Random Forest,target_class,25,840,360,Low Signal-to-Noise,1.0,High,1.0,0.8361,0.1639,Moderate,Test model robustness with irrelevant features + Overfitting detection,Validate overfitting warning systems; Test AI explanation generation; Validate chart rendering performance; Test responsive design elements,0.79 - 0.89,0.75 - 0.95,0.70 - 0.90,0.76 - 0.86,0.81 - 0.89,First 5 features should dominate,Only informative features should have significant importance,Verify noise features have minimal SHAP values,< 5 seconds,All charts display correctly,Metrics match backend calculations,UI responsive on different screen sizes,Optimal threshold around 0.5,Precision-recall tradeoff visible,ROC curve should show good separation from diagonal,Good discrimination (AUC 0.75-0.85),Test AI explanation button functionality,AI explanations should be contextually relevant,AI should correctly interpret the metrics,Check if overfitting warning appears; Test with different browser sizes; Check chart zoom and interaction features; Verify AI explanation with complex cases,All metrics display correctly; Charts render without errors; AI explanations generate successfully; Overfitting indicators should be visible,"Any crashes, incorrect calculations, missing charts, or non-responsive UI elements",Focus on overfitting detection and warnings,Many features may show minimal importance; Large performance gap between train/test,test_datasets\noisy_feature_classification\random_forest_overfitted_model.joblib,,test_datasets/noisy_feature_classification/train_dataset.csv,test_datasets/noisy_feature_classification/test_dataset.csv,Not Started,,,,,
noisy_feature_classification_gradient_boosting,Noisy Feature Classification,gradient_boosting,Gradient Boosting Classifier,target_class,25,840,360,Low Signal-to-Noise,1.0,High,1.0,0.8472,0.1528,Moderate,Test model robustness with irrelevant features,Test AI explanation generation; Validate chart rendering performance; Test responsive design elements,0.80 - 0.90,0.75 - 0.95,0.70 - 0.90,0.77 - 0.87,0.82 - 0.90,First 5 features should dominate,Only informative features should have significant importance,Verify noise features have minimal SHAP values,< 5 seconds,All charts display correctly,Metrics match backend calculations,UI responsive on different screen sizes,Optimal threshold around 0.5,Precision-recall tradeoff visible,ROC curve should show good separation from diagonal,Good discrimination (AUC 0.75-0.85),Test AI explanation button functionality,AI explanations should be contextually relevant,AI should correctly interpret the metrics,Test with different browser sizes; Check chart zoom and interaction features; Verify AI explanation with complex cases,All metrics display correctly; Charts render without errors; AI explanations generate successfully; Overfitting indicators should be visible,"Any crashes, incorrect calculations, missing charts, or non-responsive UI elements",Focus on general performance metrics and interpretability,Many features may show minimal importance,test_datasets\noisy_feature_classification\gradient_boosting_model.joblib,,test_datasets/noisy_feature_classification/train_dataset.csv,test_datasets/noisy_feature_classification/test_dataset.csv,Not Started,,,,,
noisy_feature_classification_logistic_regression,Noisy Feature Classification,logistic_regression,Logistic Regression,target_class,25,840,360,Low Signal-to-Noise,1.0,High,0.7048,0.6861,0.0187,None/Minimal,Test model robustness with irrelevant features,Test AI explanation generation; Validate chart rendering performance; Test responsive design elements,0.64 - 0.74,0.75 - 0.95,0.70 - 0.90,0.61 - 0.71,0.66 - 0.74,First 5 features should dominate,Only informative features should have significant importance,Verify noise features have minimal SHAP values,< 5 seconds,All charts display correctly,Metrics match backend calculations,UI responsive on different screen sizes,Optimal threshold around 0.5,Precision-recall tradeoff visible,ROC curve should be moderately above diagonal,Fair discrimination (AUC 0.65-0.75),Test AI explanation button functionality,AI explanations should be contextually relevant,AI should correctly interpret the metrics,Test with different browser sizes; Check chart zoom and interaction features; Verify AI explanation with complex cases,All metrics display correctly; Charts render without errors; AI explanations generate successfully,"Any crashes, incorrect calculations, missing charts, or non-responsive UI elements",Focus on general performance metrics and interpretability,Many features may show minimal importance,test_datasets\noisy_feature_classification\logistic_regression_model.joblib,test_datasets\noisy_feature_classification\logistic_regression_scaler.joblib,test_datasets/noisy_feature_classification/train_dataset.csv,test_datasets/noisy_feature_classification/test_dataset.csv,Not Started,,,,,
noisy_feature_classification_decision_tree_simple,Noisy Feature Classification,decision_tree_simple,Simple Decision Tree,target_class,25,840,360,Low Signal-to-Noise,1.0,High,0.8214,0.7361,0.0853,Mild,Test model robustness with irrelevant features,Test AI explanation generation; Validate chart rendering performance; Test responsive design elements,0.69 - 0.79,0.75 - 0.95,0.70 - 0.90,0.66 - 0.76,0.71 - 0.79,First 5 features should dominate,Only informative features should have significant importance,Verify noise features have minimal SHAP values,< 5 seconds,All charts display correctly,Metrics match backend calculations,UI responsive on different screen sizes,Optimal threshold around 0.5,Precision-recall tradeoff visible,ROC curve should be moderately above diagonal,Fair discrimination (AUC 0.65-0.75),Test AI explanation button functionality,AI explanations should be contextually relevant,AI should correctly interpret the metrics,Test with different browser sizes; Check chart zoom and interaction features; Verify AI explanation with complex cases,All metrics display correctly; Charts render without errors; AI explanations generate successfully,"Any crashes, incorrect calculations, missing charts, or non-responsive UI elements",Focus on general performance metrics and interpretability,Many features may show minimal importance,test_datasets\noisy_feature_classification\decision_tree_simple_model.joblib,,test_datasets/noisy_feature_classification/train_dataset.csv,test_datasets/noisy_feature_classification/test_dataset.csv,Not Started,,,,,
noisy_feature_classification_extra_trees,Noisy Feature Classification,extra_trees,Extra Trees Classifier,target_class,25,840,360,Low Signal-to-Noise,1.0,High,0.9976,0.8583,0.1393,Moderate,Test model robustness with irrelevant features,Test AI explanation generation; Validate chart rendering performance; Test responsive design elements,0.81 - 0.91,0.75 - 0.95,0.70 - 0.90,0.78 - 0.88,0.83 - 0.91,First 5 features should dominate,Only informative features should have significant importance,Verify noise features have minimal SHAP values,< 5 seconds,All charts display correctly,Metrics match backend calculations,UI responsive on different screen sizes,Optimal threshold around 0.5,Precision-recall tradeoff visible,ROC curve should bow strongly toward top-left,Excellent discrimination (AUC > 0.85),Test AI explanation button functionality,AI explanations should be contextually relevant,AI should correctly interpret the metrics,Test with different browser sizes; Check chart zoom and interaction features; Verify AI explanation with complex cases,All metrics display correctly; Charts render without errors; AI explanations generate successfully; Overfitting indicators should be visible,"Any crashes, incorrect calculations, missing charts, or non-responsive UI elements",Focus on general performance metrics and interpretability,Many features may show minimal importance,test_datasets\noisy_feature_classification\extra_trees_model.joblib,,test_datasets/noisy_feature_classification/train_dataset.csv,test_datasets/noisy_feature_classification/test_dataset.csv,Not Started,,,,,
